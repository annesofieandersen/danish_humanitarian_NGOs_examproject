{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35087e08",
   "metadata": {},
   "source": [
    "# Data Processing of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f6ade7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:57:36.854478Z",
     "start_time": "2021-06-15T08:57:27.527752Z"
    }
   },
   "outputs": [],
   "source": [
    "#import relevant packages \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime #To check start and end time when running code\n",
    "from tqdm import tqdm #This is for creating progress bars.\n",
    "import logging #This is to provide logging of information when running the LDA\n",
    "import sys #This is to disable logging when it's no longer needed\n",
    "import pickle #To store and open previously saved machine learning models \n",
    "\n",
    "#import nlkt libaries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer # Porter is used below. This is an alternative, harsher stemmer. \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#language detection libaries\n",
    "from langdetect import detect\n",
    "import fasttext\n",
    "\n",
    "#Importing packages for data visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import packages for regular expressions \n",
    "import regex\n",
    "import re\n",
    "\n",
    "#Importing NLTK and NLP packages\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec70bb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:57:41.654059Z",
     "start_time": "2021-06-15T08:57:36.874402Z"
    }
   },
   "outputs": [],
   "source": [
    "#read in data - here we have scraped data in two iterations \n",
    "df_12 = pd.read_excel('tweets_12_actors_15maj.xlsx', index_col=0)\n",
    "df_new = pd.read_excel('tweets_new_actors_18maj.xlsx', index_col=0)\n",
    "df_new_12_new = pd.read_excel('tweets_12_actors_15-26maj.xlsx', index_col=0)\n",
    "df_new_1 = pd.read_excel('tweets_new_actors_19-26maj.xlsx', index_col=0)\n",
    "df_4 = pd.read_excel('tweets_4_new_actors_.xlsx', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc07d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:57:41.685917Z",
     "start_time": "2021-06-15T08:57:41.657350Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating one data set \n",
    "data = pd.concat([df_12, df_new, df_new_12_new, \n",
    "                  df_new_1, df_4], join='inner', ignore_index=True)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7146048f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:57:52.210606Z",
     "start_time": "2021-06-15T08:57:52.203301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset: (12176, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total dataset:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c668610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:57:59.219729Z",
     "start_time": "2021-06-15T08:57:59.158416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset: (12139, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet</th>\n",
       "      <th>date_convert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@PlanBornefonden</td>\n",
       "      <td>13-√•rige Larissa bor i Sahel-regionen, og var ...</td>\n",
       "      <td>2021-05-14 09:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PlanBornefonden</td>\n",
       "      <td>Vi √∏nsker alle muslimer en god Eid i aften! Ei...</td>\n",
       "      <td>2021-05-12 14:00:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@PlanBornefonden</td>\n",
       "      <td>Kom til samtalek√∏kken med @BosseStine og @Clau...</td>\n",
       "      <td>2021-05-12 11:58:03</td>\n",
       "      <td>RT @dorthe10:</td>\n",
       "      <td>2021-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@PlanBornefonden</td>\n",
       "      <td>Mali, Burkina Faso og Niger - ogs√• kendt som d...</td>\n",
       "      <td>2021-05-12 10:00:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@PlanBornefonden</td>\n",
       "      <td>Vores seje kollega Iben √òstergaard Markussen f...</td>\n",
       "      <td>2021-05-12 09:23:14</td>\n",
       "      <td>RT @dorthe10:</td>\n",
       "      <td>2021-05-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              actor                                              tweet  \\\n",
       "0  @PlanBornefonden  13-√•rige Larissa bor i Sahel-regionen, og var ...   \n",
       "1  @PlanBornefonden  Vi √∏nsker alle muslimer en god Eid i aften! Ei...   \n",
       "2  @PlanBornefonden  Kom til samtalek√∏kken med @BosseStine og @Clau...   \n",
       "3  @PlanBornefonden  Mali, Burkina Faso og Niger - ogs√• kendt som d...   \n",
       "4  @PlanBornefonden  Vores seje kollega Iben √òstergaard Markussen f...   \n",
       "\n",
       "                 date         retweet date_convert  \n",
       "0 2021-05-14 09:03:00             NaN   2021-05-14  \n",
       "1 2021-05-12 14:00:02             NaN   2021-05-12  \n",
       "2 2021-05-12 11:58:03  RT @dorthe10:    2021-05-12  \n",
       "3 2021-05-12 10:00:02             NaN   2021-05-12  \n",
       "4 2021-05-12 09:23:14  RT @dorthe10:    2021-05-12  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we found out that @Feministisk_DK is a political party\n",
    "data = data[data.actor != '@Feministisk_DK']\n",
    "print(\"Total dataset:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabfc271",
   "metadata": {},
   "source": [
    "## Extracting #hashtags, @mentions and emojis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839b536f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:58:41.543314Z",
     "start_time": "2021-06-15T08:58:41.523529Z"
    }
   },
   "outputs": [],
   "source": [
    "#make sure all tweets are strings\n",
    "type(data.tweet[0])\n",
    "data['tweet'] = data['tweet'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64250628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:58:47.960407Z",
     "start_time": "2021-06-15T08:58:47.810832Z"
    }
   },
   "outputs": [],
   "source": [
    "#Saving @ mentions in another column \n",
    "mentions = []\n",
    "for index, s in data.tweet.iteritems():\n",
    "    results = []\n",
    "    if '@' in s:\n",
    "        result = re.findall(\"(?<![@\\w])@(\\w{1,25})\", s)\n",
    "        results.append(', '.join(result))\n",
    "    else:\n",
    "        results = None\n",
    "    mentions.append(results)\n",
    "\n",
    "data['@mentions'] = mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13763bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:58:54.291918Z",
     "start_time": "2021-06-15T08:58:54.130405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving list of #hashtags in another column before cleaning text\n",
    "hashtags = []\n",
    "for index, s in data.tweet.iteritems():\n",
    "    results = []\n",
    "    if '#' in s:\n",
    "        result = re.findall(\"(?<![@\\w])#(\\w{1,25})\", s)\n",
    "        # make for loop saving the # \n",
    "        #hashtags.append(result)\n",
    "        results.append(' '.join(result))\n",
    "    else:\n",
    "        results = ''\n",
    "    hashtags.append(results)\n",
    "\n",
    "data['#hashtags'] = hashtags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e8d3f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:59:01.436794Z",
     "start_time": "2021-06-15T08:59:01.306103Z"
    }
   },
   "outputs": [],
   "source": [
    "hashtags_1 = []\n",
    "for row in hashtags:\n",
    "    item = str(row)\n",
    "    item = re.sub('\\[', ' ', item) # only keeping letters\n",
    "    item = re.sub('\\]', ' ', item) # only keeping letters\n",
    "    item = re.sub('\\'', ' ', item) # only keeping letters\n",
    "    item = re.sub(r'\\s+', \" \", item) #remove more whitespaces\n",
    "    hashtags_1.append(item)\n",
    "    \n",
    "data['#hashtags'] = hashtags_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42bc97c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:59:08.202562Z",
     "start_time": "2021-06-15T08:59:08.047552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving list of emojis (üôÑü§î') in another column before cleaning text\n",
    "emojis = []\n",
    "\n",
    "#We extract all emojis but also all characters (which we remove below)\n",
    "for index, s in data.tweet.iteritems():\n",
    "        result = re.findall(r'[^\\w\\s,]', s)\n",
    "        emojis.append(', '.join(result))\n",
    "\n",
    "data['emojis'] = emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2391bb37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:59:13.990707Z",
     "start_time": "2021-06-15T08:59:13.776239Z"
    }
   },
   "outputs": [],
   "source": [
    "#we need to remove all characters from \n",
    "cleaned = []\n",
    "\n",
    "for characters in data['emojis']:\n",
    "    #item = re.sub(r'@\\S+', \"\", text) #removing @mentions\n",
    "    item = regex.sub(r'\\p{PUNCTUATION}', \"\", characters) #remove punctaion\n",
    "    item = re.sub(r'\\s+', \" \", item) #remove more whitespaces\n",
    "    cleaned.append(item)\n",
    "    \n",
    "data['emojis'] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6502044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:59:19.675171Z",
     "start_time": "2021-06-15T08:59:19.665079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' üëè '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.emojis[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4dbebbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:59:24.630425Z",
     "start_time": "2021-06-15T08:59:24.612130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet</th>\n",
       "      <th>date_convert</th>\n",
       "      <th>@mentions</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@PlanBornefonden</td>\n",
       "      <td>13-√•rige Larissa bor i Sahel-regionen, og var ...</td>\n",
       "      <td>2021-05-14 09:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PlanBornefonden</td>\n",
       "      <td>Vi √∏nsker alle muslimer en god Eid i aften! Ei...</td>\n",
       "      <td>2021-05-12 14:00:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@PlanBornefonden</td>\n",
       "      <td>Kom til samtalek√∏kken med @BosseStine og @Clau...</td>\n",
       "      <td>2021-05-12 11:58:03</td>\n",
       "      <td>RT @dorthe10:</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>[BosseStine, ClausMeyerDK]</td>\n",
       "      <td>dkfood</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              actor                                              tweet  \\\n",
       "0  @PlanBornefonden  13-√•rige Larissa bor i Sahel-regionen, og var ...   \n",
       "1  @PlanBornefonden  Vi √∏nsker alle muslimer en god Eid i aften! Ei...   \n",
       "2  @PlanBornefonden  Kom til samtalek√∏kken med @BosseStine og @Clau...   \n",
       "\n",
       "                 date         retweet date_convert  \\\n",
       "0 2021-05-14 09:03:00             NaN   2021-05-14   \n",
       "1 2021-05-12 14:00:02             NaN   2021-05-12   \n",
       "2 2021-05-12 11:58:03  RT @dorthe10:    2021-05-12   \n",
       "\n",
       "                    @mentions #hashtags emojis  \n",
       "0                        None                   \n",
       "1                        None                   \n",
       "2  [BosseStine, ClausMeyerDK]   dkfood          "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting new agregated dataset \n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76eee77",
   "metadata": {},
   "source": [
    "## Pre-processing of tweets and retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b234e639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:00:10.599188Z",
     "start_time": "2021-06-15T09:00:10.591935Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define remove emojis function \n",
    "RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "\n",
    "def strip_emoji(text):\n",
    "    return RE_EMOJI.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7541c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:00:16.944259Z",
     "start_time": "2021-06-15T09:00:16.927397Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define another remove emojis function \n",
    "RE_EMOJI2 =  re.compile(u'['\n",
    "    u'\\U0001F300-\\U0001F64F'\n",
    "    u'\\U0001F680-\\U0001F6FF'\n",
    "    u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "    re.UNICODE)\n",
    "\n",
    "def strip_emoji_2(text):\n",
    "    return RE_EMOJI2.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97b11fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:00:22.820315Z",
     "start_time": "2021-06-15T09:00:22.814083Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36dd5310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:00:31.260683Z",
     "start_time": "2021-06-15T09:00:31.244676Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove @ from actor column\n",
    "data['actor'] = data.actor.str.replace(r'@','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f931223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:00:39.723653Z",
     "start_time": "2021-06-15T09:00:37.387429Z"
    }
   },
   "outputs": [],
   "source": [
    "#cleaning tweets using regex\n",
    "\n",
    "cleaned = []\n",
    "\n",
    "for text in data['tweet']:\n",
    "    item = re.sub(r'@\\S+', \"\", text) #removing @mentions\n",
    "    item = re.sub(r'#(\\w+)', \"\", item) #removing hashtags \n",
    "    item = re.sub(r'&amp;', \"\", item) #remove &\n",
    "    \n",
    "    #remove emojis and lower case \n",
    "    item = re.sub(r'1‚É£', \"\", item)\n",
    "    item = re.sub(r'2‚É£', \"\", item)\n",
    "    item = re.sub(r'3‚É£', \"\", item)\n",
    "    item = re.sub(r'4‚É£', \"\", item)\n",
    "    item = re.sub(r'2Ô∏è‚É£9Ô∏è‚É£', \"\", item)\n",
    "    item = strip_emoji(item) #removing emojis \n",
    "    item = strip_emoji(item) #removing emojis \n",
    "    item = strip_emoji_2(item) #removing emojis \n",
    "    item = remove_emojis(item)\n",
    "    item = re.sub(r\"[‚îª‚îÉ‚îÅ‚î≥‚îì‚îè‚îõ‚îó]\",\"\", item)\n",
    "    item = re.sub(r\"\\u202F|\\u2069|\\u200d|\\u2066\",\"\", item)\n",
    "    \n",
    "    \n",
    "    item = re.sub(r'\\d+', \"\", item) #remove digits first, otherwise we get eg. 13√•rige\n",
    "    item = re.sub(r'(^[a-zA-Z]+$)', '', item) # only keeping letters \n",
    "    item = item.lower() #lower cases \n",
    "    \n",
    "    item = regex.sub(r'\\p{PUNCTUATION}', \"\", item) #remove punctaion\n",
    "    item = re.sub(r'\\s+', \" \", item) #remove more whitespaces\n",
    "    item = re.sub(r'http\\S+', '', item) #remove urls\n",
    "    item = item.rstrip()\n",
    "  \n",
    "    cleaned.append(item)\n",
    "    \n",
    "data['clean_text'] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b8bdb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:00:52.257942Z",
     "start_time": "2021-06-15T09:00:48.758347Z"
    }
   },
   "outputs": [],
   "source": [
    "string_text = []\n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    if row.actor == 'MissionEast':\n",
    "        string = re.sub(r'mission √∏st', '', row.clean_text)\n",
    "        string_text.append(string)\n",
    "    else:\n",
    "        string_text.append(row.clean_text)\n",
    "    #item = re.sub(r'mission √∏st', '', words\n",
    "\n",
    "data['clean_text'] = string_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734467ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:00:55.020871Z",
     "start_time": "2021-06-15T09:00:55.010053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det er rystende at h√∏re om den ulykkelige situation i Indien. Med bidrag til @IndianRedCross er Danmark bl.a. med til at st√∏tte ambulanceservice, indk√∏b af beskyttelsesudstyr samt stoppe misinformation om sygdommen. Helt afg√∏rende indsatser for at bek√¶mpe pandemien. #dkpol #dkaid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'det er rystende at h√∏re om den ulykkelige situation i indien med bidrag til er danmark bla med til at st√∏tte ambulanceservice indk√∏b af beskyttelsesudstyr samt stoppe misinformation om sygdommen helt afg√∏rende indsatser for at bek√¶mpe pandemien'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.tweet[23])\n",
    "data.clean_text[23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd03a1",
   "metadata": {},
   "source": [
    "* We are keeping names, as these might refer to important actors, which we want to explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6c6fb",
   "metadata": {},
   "source": [
    "## Language Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5320ec44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:01:27.998529Z",
     "start_time": "2021-06-15T09:01:27.435046Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "#PRETRAINED_MODEL_PATH \n",
    "fast = fasttext.load_model('/Users/Sofie/Desktop/tmp/lid.176.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0f5fe55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:01:34.506624Z",
     "start_time": "2021-06-15T09:01:34.497525Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions for language classification\n",
    " \n",
    "def tweet_cleaner(x):\n",
    "    '''\n",
    "    Cleans a str object x by:\n",
    "    replacing '\\n' with ' '\n",
    "    replacing '#' with ''\n",
    "    removing urls\n",
    "    '''\n",
    "    x = x.replace('\\n', ' ')\n",
    "    x = x.replace('#', '')\n",
    "    x = re.sub(r'(https?:\\/\\/)(\\s)*(www\\.)?(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*', '', x)\n",
    "    x = x.strip()\n",
    "    return x\n",
    " \n",
    "# fasttext function - language detector\n",
    "def fast_detector(x):\n",
    "    x = tweet_cleaner(x)\n",
    "    try:\n",
    "        return fast.predict(x)[0][0][-2:]\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96202705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:01:40.959249Z",
     "start_time": "2021-06-15T09:01:40.950216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: da\n"
     ]
    }
   ],
   "source": [
    "#Checking how the language detector works\n",
    "print('Language:', fast_detector(data.tweet[117]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7b62c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:01:48.622162Z",
     "start_time": "2021-06-15T09:01:46.856001Z"
    }
   },
   "outputs": [],
   "source": [
    "#adding language column \n",
    "data['language'] = data[\"tweet\"].apply(lambda x: fast_detector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f00bcb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:01:52.994045Z",
     "start_time": "2021-06-15T09:01:52.909539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet</th>\n",
       "      <th>date_convert</th>\n",
       "      <th>@mentions</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>af</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>az</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>3330</td>\n",
       "      <td>9201</td>\n",
       "      <td>5781</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "      <td>2044</td>\n",
       "      <td>2589</td>\n",
       "      <td>1534</td>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ht</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lb</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ls</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lt</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mn</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>57</td>\n",
       "      <td>238</td>\n",
       "      <td>133</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          actor  tweet  date  retweet  date_convert  @mentions  #hashtags  \\\n",
       "language                                                                    \n",
       "af            1      1     1        0             1          1          1   \n",
       "ar            2      2     2        2             2          0          2   \n",
       "az            1      1     1        0             1          1          1   \n",
       "bg            1      1     1        0             1          0          1   \n",
       "cs            3      3     3        0             3          3          3   \n",
       "da         9201   9201  9201     3330          9201       5781       9201   \n",
       "de           23     23    23        8            23         17         23   \n",
       "ds            1      1     1        1             1          0          1   \n",
       "en         2589   2589  2589     2044          2589       1534       2589   \n",
       "es           13     13    13        1            13         10         13   \n",
       "et            1      1     1        0             1          0          1   \n",
       "fi            4      4     4        0             4          0          4   \n",
       "fr            9      9     9        7             9          3          9   \n",
       "ht            4      4     4        4             4          0          4   \n",
       "hu            2      2     2        0             2          1          2   \n",
       "id            2      2     2        0             2          2          2   \n",
       "it            2      2     2        0             2          2          2   \n",
       "kw            1      1     1        0             1          0          1   \n",
       "lb            1      1     1        0             1          1          1   \n",
       "ls            1      1     1        0             1          0          1   \n",
       "lt            1      1     1        0             1          0          1   \n",
       "mn            1      1     1        0             1          1          1   \n",
       "nl            4      4     4        2             4          1          4   \n",
       "no          238    238   238       57           238        133        238   \n",
       "pl            1      1     1        0             1          1          1   \n",
       "pt            2      2     2        1             2          1          2   \n",
       "ru            1      1     1        0             1          1          1   \n",
       "sv           22     22    22        8            22         13         22   \n",
       "tr            3      3     3        0             3          3          3   \n",
       "zh            4      4     4        0             4          2          4   \n",
       "\n",
       "          emojis  clean_text  \n",
       "language                      \n",
       "af             1           1  \n",
       "ar             2           2  \n",
       "az             1           1  \n",
       "bg             1           1  \n",
       "cs             3           3  \n",
       "da          9201        9201  \n",
       "de            23          23  \n",
       "ds             1           1  \n",
       "en          2589        2589  \n",
       "es            13          13  \n",
       "et             1           1  \n",
       "fi             4           4  \n",
       "fr             9           9  \n",
       "ht             4           4  \n",
       "hu             2           2  \n",
       "id             2           2  \n",
       "it             2           2  \n",
       "kw             1           1  \n",
       "lb             1           1  \n",
       "ls             1           1  \n",
       "lt             1           1  \n",
       "mn             1           1  \n",
       "nl             4           4  \n",
       "no           238         238  \n",
       "pl             1           1  \n",
       "pt             2           2  \n",
       "ru             1           1  \n",
       "sv            22          22  \n",
       "tr             3           3  \n",
       "zh             4           4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#expecting language \n",
    "\n",
    "#most tweets with other lang than da or en are miscategorization due to emojis and links \n",
    "data.groupby(data.language).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6be9583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:02:06.600388Z",
     "start_time": "2021-06-15T09:02:06.568984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet</th>\n",
       "      <th>date_convert</th>\n",
       "      <th>@mentions</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>ActionAidDK</td>\n",
       "      <td>ÿ¥ŸÉÿ±ÿß ŸÑŸáŸàŸÑÿßÿ°  ÿßŸÑŸÜÿßÿ¥ÿ∑ŸäŸÜ ÿßŸÑŸÖÿπÿ™ÿµŸÖŸäŸÜ ÿ£ŸÖÿßŸÖ ŸÖÿ®ŸÜŸâ ÿßŸÑÿ®ÿ±...</td>\n",
       "      <td>2021-03-17 15:04:40</td>\n",
       "      <td>RT @AAPalestine:</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ÿ¥ŸÉÿ±ÿß ŸÑŸáŸàŸÑÿßÿ° ÿßŸÑŸÜÿßÿ¥ÿ∑ŸäŸÜ ÿßŸÑŸÖÿπÿ™ÿµŸÖŸäŸÜ ÿ£ŸÖÿßŸÖ ŸÖÿ®ŸÜŸâ ÿßŸÑÿ®ÿ±ŸÑ...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>ActionAidDK</td>\n",
       "      <td>ÿ™ŸÖ  ÿ•ÿπÿ∑ÿßÿ° ŸÑŸÇÿßÿ≠ ŸÅŸäÿ±Ÿàÿ≥ ŸÉŸàÿ±ŸàŸÜÿß ŸÑŸÑÿ•ÿ≥ÿ±ÿßÿ¶ŸÑŸäŸäŸÜ ÿßŸÑÿ∞ŸäŸÜ ...</td>\n",
       "      <td>2021-03-16 09:53:27</td>\n",
       "      <td>RT @AAPalestine:</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>None</td>\n",
       "      <td>ŸÖÿπÿß_ŸÑŸÑŸÖÿ∑ÿßŸÑÿ®ÿ©_ÿ®ŸÑŸÇÿßÿ≠_ŸÖÿ¨ÿßŸÜŸä_</td>\n",
       "      <td></td>\n",
       "      <td>ÿ™ŸÖ ÿ•ÿπÿ∑ÿßÿ° ŸÑŸÇÿßÿ≠ ŸÅŸäÿ±Ÿàÿ≥ ŸÉŸàÿ±ŸàŸÜÿß ŸÑŸÑÿ•ÿ≥ÿ±ÿßÿ¶ŸÑŸäŸäŸÜ ÿßŸÑÿ∞ŸäŸÜ Ÿä...</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            actor                                              tweet  \\\n",
       "2579  ActionAidDK  ÿ¥ŸÉÿ±ÿß ŸÑŸáŸàŸÑÿßÿ°  ÿßŸÑŸÜÿßÿ¥ÿ∑ŸäŸÜ ÿßŸÑŸÖÿπÿ™ÿµŸÖŸäŸÜ ÿ£ŸÖÿßŸÖ ŸÖÿ®ŸÜŸâ ÿßŸÑÿ®ÿ±...   \n",
       "2587  ActionAidDK  ÿ™ŸÖ  ÿ•ÿπÿ∑ÿßÿ° ŸÑŸÇÿßÿ≠ ŸÅŸäÿ±Ÿàÿ≥ ŸÉŸàÿ±ŸàŸÜÿß ŸÑŸÑÿ•ÿ≥ÿ±ÿßÿ¶ŸÑŸäŸäŸÜ ÿßŸÑÿ∞ŸäŸÜ ...   \n",
       "\n",
       "                    date            retweet date_convert @mentions  \\\n",
       "2579 2021-03-17 15:04:40  RT @AAPalestine:    2021-03-17      None   \n",
       "2587 2021-03-16 09:53:27  RT @AAPalestine:    2021-03-16      None   \n",
       "\n",
       "                        #hashtags emojis  \\\n",
       "2579                                       \n",
       "2587   ŸÖÿπÿß_ŸÑŸÑŸÖÿ∑ÿßŸÑÿ®ÿ©_ÿ®ŸÑŸÇÿßÿ≠_ŸÖÿ¨ÿßŸÜŸä_           \n",
       "\n",
       "                                             clean_text language  \n",
       "2579  ÿ¥ŸÉÿ±ÿß ŸÑŸáŸàŸÑÿßÿ° ÿßŸÑŸÜÿßÿ¥ÿ∑ŸäŸÜ ÿßŸÑŸÖÿπÿ™ÿµŸÖŸäŸÜ ÿ£ŸÖÿßŸÖ ŸÖÿ®ŸÜŸâ ÿßŸÑÿ®ÿ±ŸÑ...       ar  \n",
       "2587  ÿ™ŸÖ ÿ•ÿπÿ∑ÿßÿ° ŸÑŸÇÿßÿ≠ ŸÅŸäÿ±Ÿàÿ≥ ŸÉŸàÿ±ŸàŸÜÿß ŸÑŸÑÿ•ÿ≥ÿ±ÿßÿ¶ŸÑŸäŸäŸÜ ÿßŸÑÿ∞ŸäŸÜ Ÿä...       ar  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspection \n",
    "data.loc[data.language == 'ar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "186d37ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:02:14.287409Z",
     "start_time": "2021-06-15T09:02:14.277235Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-f8c2eed03064>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.language[english_tweets_fail_detection[0]] = 'en'\n",
      "<ipython-input-27-f8c2eed03064>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.language[english_tweets_fail_detection[1]] = 'en'\n"
     ]
    }
   ],
   "source": [
    "#to english from de \n",
    "english_tweets_fail_detection = [2174, 2749]\n",
    "\n",
    "data.language[english_tweets_fail_detection[0]] = 'en'\n",
    "data.language[english_tweets_fail_detection[1]] = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24099d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:02:37.904613Z",
     "start_time": "2021-06-15T09:02:37.899138Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove tweets if language is not Danish or English \n",
    "\n",
    "#where language detector is not consistent (ES, SE, DE)\n",
    "tweets_remove_id = [2588, 8456, 8447, 8422, 7271, 4614, 3383, 8570, 8574, 11998] \n",
    "remove_language = ['ar', 'fr', 'ht', 'pt'] #no text in ht \n",
    "\n",
    "#We save these in objects now, so we can remove them after the retweet networks\n",
    "#This is a methodological choice as the retweets are essential to understand the \n",
    "#relations betweens actors through retweets, but as the text can not be used for \n",
    "#PCA or other models relying on text data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b82d4",
   "metadata": {},
   "source": [
    "### Methodological choices regarding languages of twwets\n",
    "\n",
    "* We sort out non-Danish tweet to increase the validity. In this way, we loose some data, but importantly, we are able to conclude on the findings setting them in relation to a national context, which we can investigate qualitatively. \n",
    "* The language detector is not good enough to detect Danish and Norwegian tweets from oneanother. Most tweets detected as Norwegians tweets are actually written in Danish, and the rest uses a lot of the same words. Furhter, are there some tweets in Norwegian, the words will proberbly not be used in the PCA anyways as they appear to seldom. Therefore, we keep all norwegian tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438b754",
   "metadata": {},
   "source": [
    "## Stopwords and Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf402ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:07:43.876688Z",
     "start_time": "2021-06-15T09:07:43.865514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of orignial stopword list: 94\n",
      "length of new stopword list: 135\n"
     ]
    }
   ],
   "source": [
    "#Stopwords \n",
    "\n",
    "stop_words_dk = set(stopwords.words('danish')) \n",
    "stop_words_en = set(stopwords.words('english')) \n",
    "\n",
    "# we add more stop words \n",
    "danish_words = ['kan', 's√•', 'f√•', 'se', 'ved', 'ser', 'hvordan', 'mere', 'nye', 'derfor', \n",
    "                'f√•r', 'g√∏re ', 'g√•r', 'bla', 'mest', 'g√∏r', 'stor', 'del', 'n√•', 'b√•de', \n",
    "                't√¶t', 'andre', 'bruge', 'dag', 'sige', 'vores', 'komme', 'siger', 'sagde',\n",
    "               'ny', 'mellem', 'omkring', 'pga', 'fordi', 'g√•', 'bare' , 'lidt', 's√¶tte', \n",
    "                'of', 'on', 'the']\n",
    "\n",
    "\n",
    "\n",
    "print(\"length of orignial stopword list:\", len(stop_words_dk))\n",
    "\n",
    "for word in danish_words:\n",
    "    stop_words_dk.add(word)\n",
    "\n",
    "print(\"length of new stopword list:\", len(stop_words_dk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b56f1549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:08:06.167010Z",
     "start_time": "2021-06-15T09:07:57.722306Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "\n",
    "#TOKENNIZE WORDS\n",
    "data[\"words\"] = data[\"clean_text\"].str.split()\n",
    "\n",
    "#REMOVE ENGLISH STOPWORDS IF LANGUAGE IS ENGLISH, ELSE REMOVE DANISH STOPWORDS\n",
    "data[\"without_stopwords\"] = [[x for x in row.words if x not in \n",
    "                              (stop_words_en if row.language == 'en' else stop_words_dk)]\n",
    "                             for row in data.iloc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e6f0321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:08:21.136655Z",
     "start_time": "2021-06-15T09:08:19.798926Z"
    }
   },
   "outputs": [],
   "source": [
    "#lemmatize danish tweets \n",
    "import lemmy\n",
    "\n",
    "# Create an instance of the standalone lemmatizer.\n",
    "lemmatizer = lemmy.load(\"da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2703d489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:08:27.450956Z",
     "start_time": "2021-06-15T09:08:26.252898Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating a column with lemmas  (Danish)\n",
    "lemmas = []\n",
    "\n",
    "for words in data['without_stopwords']:\n",
    "    lemmas_sentence = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(\"\", word)\n",
    "        lemmas_sentence.append(lemma[0])\n",
    "    lemmas.append(lemmas_sentence)\n",
    "        \n",
    "        \n",
    "data['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36e15c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:08:45.222591Z",
     "start_time": "2021-06-15T09:08:45.198198Z"
    }
   },
   "outputs": [],
   "source": [
    "#putting words together \n",
    "data['proc_text'] = data['lemmas'].apply(\n",
    "                     lambda x: \" \".join( x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d6660",
   "metadata": {},
   "source": [
    "## Bigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf5540c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:08:57.924600Z",
     "start_time": "2021-06-15T09:08:57.560395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12139/12139 [00:00<00:00, 43588.81it/s]\n"
     ]
    }
   ],
   "source": [
    "#We have the unigrams in the lemmas \n",
    "\n",
    "tqdm.pandas() #Creates a progress bar. Use progress_apply instead of apply.\n",
    "#Defining a function that will create bigrams \n",
    "def bigrams(doc):\n",
    "    \n",
    "    bigrams = [] #Empty list to save the bigrams\n",
    "    \n",
    "    for bigram in list(nltk.bigrams(doc)):  #Creating bigrams and iterating over them\n",
    "        bigrams.append(\"_\".join(bigram))    #Connecting each bigram pair with an underscore and saving to list\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "#Creating a column with bigrams\n",
    "data['bigrams'] = data.lemmas.progress_apply(lambda x: bigrams(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6440e5b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:10:26.326266Z",
     "start_time": "2021-06-15T09:10:21.738982Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating final data string for the words we want to include in the analyses\n",
    "\n",
    "data['proc_text_all'] = [row.proc_text + ' ' + ' '.join(row.bigrams) + row['#hashtags'] \n",
    "                            for row in data.iloc] #includes, tokens, bigrams and hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e159e95",
   "metadata": {},
   "source": [
    "## Pre-processesing retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6eca571c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:11:30.482990Z",
     "start_time": "2021-06-15T09:11:30.472673Z"
    }
   },
   "outputs": [],
   "source": [
    "#make all retweets to strings\n",
    "data['retweet'] = data['retweet'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7bc8eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:11:36.589130Z",
     "start_time": "2021-06-15T09:11:36.539742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:4: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-38-1f54a57ce3ca>:4: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if retweet is 'nan':\n"
     ]
    }
   ],
   "source": [
    "#removing RT from retweets\n",
    "retweets = []\n",
    "for retweet in data['retweet']:\n",
    "    if retweet is 'nan':\n",
    "        item = None\n",
    "    else:\n",
    "        item = re.sub(r'^RT ', '', retweet)\n",
    "        item = re.sub(r': ', '', item)\n",
    "    retweets.append(item)\n",
    "    \n",
    "\n",
    "data['retweet'] = retweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdf7f1",
   "metadata": {},
   "source": [
    "### Making sub-dataset only for retweets network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "668e559b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:12:40.309699Z",
     "start_time": "2021-06-15T09:12:40.245790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5465, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet</th>\n",
       "      <th>date_convert</th>\n",
       "      <th>@mentions</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>language</th>\n",
       "      <th>words</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>proc_text</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>proc_text_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PlanBornefonden</td>\n",
       "      <td>Kom til samtalek√∏kken med @BosseStine og @Clau...</td>\n",
       "      <td>2021-05-12 11:58:03</td>\n",
       "      <td>@dorthe10</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>[BosseStine, ClausMeyerDK]</td>\n",
       "      <td>dkfood</td>\n",
       "      <td></td>\n",
       "      <td>kom til samtalek√∏kken med og den maj og spis e...</td>\n",
       "      <td>da</td>\n",
       "      <td>[kom, til, samtalek√∏kken, med, og, den, maj, o...</td>\n",
       "      <td>[kom, samtalek√∏kken, maj, spis, l√¶kker, retter...</td>\n",
       "      <td>[komme, samtalek√∏kken, maj, spise, l√¶kker, ret...</td>\n",
       "      <td>komme samtalek√∏kken maj spise l√¶kker ret menu ...</td>\n",
       "      <td>[komme_samtalek√∏kken, samtalek√∏kken_maj, maj_s...</td>\n",
       "      <td>komme samtalek√∏kken maj spise l√¶kker ret menu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PlanBornefonden</td>\n",
       "      <td>Vores seje kollega Iben √òstergaard Markussen f...</td>\n",
       "      <td>2021-05-12 09:23:14</td>\n",
       "      <td>@dorthe10</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>[radioloud_dk, MaternityF]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>vores seje kollega iben √∏stergaard markussen f...</td>\n",
       "      <td>da</td>\n",
       "      <td>[vores, seje, kollega, iben, √∏stergaard, marku...</td>\n",
       "      <td>[seje, kollega, iben, √∏stergaard, markussen, f...</td>\n",
       "      <td>[sej, kollega, ibe, √∏stergaard, markusse, fort...</td>\n",
       "      <td>sej kollega ibe √∏stergaard markusse fort√¶ller ...</td>\n",
       "      <td>[sej_kollega, kollega_ibe, ibe_√∏stergaard, √∏st...</td>\n",
       "      <td>sej kollega ibe √∏stergaard markusse fort√¶ller ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PlanBornefonden</td>\n",
       "      <td>Godt at se @udviklingsmin og @JeppeKofod under...</td>\n",
       "      <td>2021-05-12 07:01:44</td>\n",
       "      <td>@anne_smith_p</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>[udviklingsmin, JeppeKofod, DanishMFA]</td>\n",
       "      <td>dkaid PURE</td>\n",
       "      <td></td>\n",
       "      <td>godt at se og understrege at den danske indsat...</td>\n",
       "      <td>da</td>\n",
       "      <td>[godt, at, se, og, understrege, at, den, dansk...</td>\n",
       "      <td>[godt, understrege, danske, indsats, sahel, fo...</td>\n",
       "      <td>[godt, understrege, dansk, indsats, sahele, fo...</td>\n",
       "      <td>godt understrege dansk indsats sahele fortsat ...</td>\n",
       "      <td>[godt_understrege, understrege_dansk, dansk_in...</td>\n",
       "      <td>godt understrege dansk indsats sahele fortsat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actor                                              tweet  \\\n",
       "0  PlanBornefonden  Kom til samtalek√∏kken med @BosseStine og @Clau...   \n",
       "1  PlanBornefonden  Vores seje kollega Iben √òstergaard Markussen f...   \n",
       "2  PlanBornefonden  Godt at se @udviklingsmin og @JeppeKofod under...   \n",
       "\n",
       "                 date        retweet date_convert  \\\n",
       "0 2021-05-12 11:58:03      @dorthe10   2021-05-12   \n",
       "1 2021-05-12 09:23:14      @dorthe10   2021-05-12   \n",
       "2 2021-05-12 07:01:44  @anne_smith_p   2021-05-12   \n",
       "\n",
       "                                @mentions     #hashtags emojis  \\\n",
       "0              [BosseStine, ClausMeyerDK]       dkfood           \n",
       "1              [radioloud_dk, MaternityF]                        \n",
       "2  [udviklingsmin, JeppeKofod, DanishMFA]   dkaid PURE           \n",
       "\n",
       "                                          clean_text language  \\\n",
       "0  kom til samtalek√∏kken med og den maj og spis e...       da   \n",
       "1  vores seje kollega iben √∏stergaard markussen f...       da   \n",
       "2  godt at se og understrege at den danske indsat...       da   \n",
       "\n",
       "                                               words  \\\n",
       "0  [kom, til, samtalek√∏kken, med, og, den, maj, o...   \n",
       "1  [vores, seje, kollega, iben, √∏stergaard, marku...   \n",
       "2  [godt, at, se, og, understrege, at, den, dansk...   \n",
       "\n",
       "                                   without_stopwords  \\\n",
       "0  [kom, samtalek√∏kken, maj, spis, l√¶kker, retter...   \n",
       "1  [seje, kollega, iben, √∏stergaard, markussen, f...   \n",
       "2  [godt, understrege, danske, indsats, sahel, fo...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [komme, samtalek√∏kken, maj, spise, l√¶kker, ret...   \n",
       "1  [sej, kollega, ibe, √∏stergaard, markusse, fort...   \n",
       "2  [godt, understrege, dansk, indsats, sahele, fo...   \n",
       "\n",
       "                                           proc_text  \\\n",
       "0  komme samtalek√∏kken maj spise l√¶kker ret menu ...   \n",
       "1  sej kollega ibe √∏stergaard markusse fort√¶ller ...   \n",
       "2  godt understrege dansk indsats sahele fortsat ...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [komme_samtalek√∏kken, samtalek√∏kken_maj, maj_s...   \n",
       "1  [sej_kollega, kollega_ibe, ibe_√∏stergaard, √∏st...   \n",
       "2  [godt_understrege, understrege_dansk, dansk_in...   \n",
       "\n",
       "                                       proc_text_all  \n",
       "0  komme samtalek√∏kken maj spise l√¶kker ret menu ...  \n",
       "1  sej kollega ibe √∏stergaard markusse fort√¶ller ...  \n",
       "2  godt understrege dansk indsats sahele fortsat ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating subset of data\n",
    "data_retweets = data.loc[data['retweet'] != 'nan']\n",
    "data_retweets = data_retweets.reset_index(drop=True)\n",
    "\n",
    "print(data_retweets.shape)\n",
    "data_retweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c973a13a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:12:53.767363Z",
     "start_time": "2021-06-15T09:12:53.752781Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove @\n",
    "data_retweets['retweet'] = data_retweets.retweet.str.replace(r'@','')\n",
    "\n",
    "data_retweets = data_retweets.drop(columns=['tweet', 'date', 'date_convert','#hashtags','clean_text','words','without_stopwords', 'proc_text', 'bigrams','lemmas', 'language', 'emojis', 'proc_text_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dc98bfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:13:01.144499Z",
     "start_time": "2021-06-15T09:13:01.131285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>retweet</th>\n",
       "      <th>@mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PlanBornefonden</td>\n",
       "      <td>dorthe10</td>\n",
       "      <td>[BosseStine, ClausMeyerDK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PlanBornefonden</td>\n",
       "      <td>dorthe10</td>\n",
       "      <td>[radioloud_dk, MaternityF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PlanBornefonden</td>\n",
       "      <td>anne_smith_p</td>\n",
       "      <td>[udviklingsmin, JeppeKofod, DanishMFA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PlanBornefonden</td>\n",
       "      <td>SeeRap</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PlanBornefonden</td>\n",
       "      <td>UNFPAEthiopia</td>\n",
       "      <td>[UNFPAEthiopia]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actor        retweet                               @mentions\n",
       "0  PlanBornefonden       dorthe10              [BosseStine, ClausMeyerDK]\n",
       "1  PlanBornefonden       dorthe10              [radioloud_dk, MaternityF]\n",
       "2  PlanBornefonden   anne_smith_p  [udviklingsmin, JeppeKofod, DanishMFA]\n",
       "3  PlanBornefonden         SeeRap                                    None\n",
       "4  PlanBornefonden  UNFPAEthiopia                         [UNFPAEthiopia]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a116c77c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:13:09.233058Z",
     "start_time": "2021-06-15T09:13:09.188261Z"
    }
   },
   "outputs": [],
   "source": [
    "#saving to desktop \n",
    "data_retweets.to_csv('data_retweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4f53a",
   "metadata": {},
   "source": [
    "## Remove tweets with other languages for text analysis\n",
    "\n",
    "* Remove **tweets_remove_id** = [2588, 8456, 8447, 8422, 7271, 4614, 3383, 8570, 8574] \n",
    "* Remove **remove_language** = ['ar', 'fr', 'ht', 'pt'] #no text in ht \n",
    "\n",
    "* Divide up Danish and English tweets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "861bfcab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:13:51.891736Z",
     "start_time": "2021-06-15T09:13:51.816070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (12139, 16)\n",
      "New shape after dropping first time: (12129, 16)\n",
      "New shape after dropping second time: (12127, 16)\n",
      "New shape after dropping second time: (12118, 16)\n",
      "New shape after dropping second time: (12114, 16)\n",
      "New shape after dropping second time: (12112, 16)\n",
      "New shape after dropping empty columns: (11957, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before:', data.shape)\n",
    "data_clean = data.drop(tweets_remove_id)\n",
    "print('New shape after dropping first time:', data_clean.shape)\n",
    "data_clean = data_clean[data_clean.language != 'ar']\n",
    "print('New shape after dropping second time:', data_clean.shape)\n",
    "data_clean = data_clean[data_clean.language != 'fr']\n",
    "print('New shape after dropping second time:', data_clean.shape)\n",
    "data_clean = data_clean[data_clean.language != 'ht']\n",
    "print('New shape after dropping second time:', data_clean.shape)\n",
    "data_clean = data_clean[data_clean.language != 'pt']\n",
    "print('New shape after dropping second time:', data_clean.shape)\n",
    "data_clean = data_clean[data_clean.proc_text != '']\n",
    "print('New shape after dropping empty columns:', data_clean.shape)\n",
    "data_clean = data_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4be0d8dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:13:58.325040Z",
     "start_time": "2021-06-15T09:13:58.302269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9449, 16)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making danish data set \n",
    "data_danish = data_clean[data_clean.language != 'en']\n",
    "data_danish = data_danish.reset_index(drop=True)\n",
    "data_danish.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c51f889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:14:08.233359Z",
     "start_time": "2021-06-15T09:14:06.333605Z"
    }
   },
   "outputs": [],
   "source": [
    "#data_danish_sub = data_danish[['actor', 'proc_text', '#hashtags']]\n",
    "data_danish.to_csv('data_danish.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24d3864e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:14:19.891697Z",
     "start_time": "2021-06-15T09:14:19.882775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gange program officielt begynde uganda etiopien sammen konsortium fem ngo st√∏tte sikre l√¶ring gennem leg barn flugte l√¶sse projekt\n",
      "true lokalsamfund sundhed f√∏devaresikkerhed st√∏tte lokal produktion udstyre ansigtsmaske s√¶be redde liv samtidig √∏ge befolkning indkomst l√¶sse projekt\n",
      "inden bygge d√¶mning kalobeyeu n√¶sten umulig gro afgr√∏de problem snarere plads gr√∏ntsag l√¶sse projekt spil vigtig rolle kris\n",
      "vide fremme platform l√¶sse projekt\n"
     ]
    }
   ],
   "source": [
    "#explore text where words are processed \n",
    "for text in data_danish.proc_text:\n",
    "    if 'l√¶sse projekt' in text:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d13408",
   "metadata": {},
   "source": [
    "**Note on Lemmatizer:**\n",
    "\n",
    "It changes the danish word\n",
    "\n",
    "* *l√¶se* to *l√¶sse*\n",
    "* *tage* to *tagge*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
